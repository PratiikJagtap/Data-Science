{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24efbd4d-5976-4be7-b92d-7ad118052d55",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fde8a1-173e-4002-a1fa-c438233866ec",
   "metadata": {},
   "source": [
    "## There are Two main types: Descriptive & Inferential Statistics.\n",
    "1) Descriptive: It describe & summarize the population by using measures of central tendency, measures of despersion.\n",
    "2) Inferential: It uses sample data to make conclusions of whole population by using hypothesis testing, probability distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befbe4f3-cf58-43bf-82af-b9d0bad18b0d",
   "metadata": {},
   "source": [
    "## Types of data: \n",
    "1) Numerical Data: There are two types continous & discrete\n",
    "- Continous: (age, weight, time) like any value that is continously changable not fixed.\n",
    "- Discrete: (shoe size, number of children,) like any value that is fixed for eg. 1,2,3...\n",
    "2) Categorical Data: There are two types Ordinal & Nominal\n",
    "- Ordinal: It is data with order. For eg(Customer reviews)\n",
    "- Nominal: It is data without order. For eg(Blood Group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c5c13c-e48e-402a-8810-031c1ec24409",
   "metadata": {},
   "source": [
    "# HARNESSING DATA (collecting, organizing, and using data in a useful way to get insights)\n",
    "## Data Sampling: It is the process of selecting small part of data from the population\n",
    "- For eg: (Population = All students,\n",
    "  Sample = The group of 100 students,\n",
    "  Data Sampling = The process of selecting those 100 students)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1aec8f-1548-4ac2-8f52-4ab267f266a5",
   "metadata": {},
   "source": [
    "## Types of Data Sampling: There are two main types Probability sampling & Non-Probability sampling\n",
    "1) Probability Sampling:\n",
    "   - Simple random sampling: In this sample get randomly selected from population & each Everyone has the same chance of being chosen For eg(Lottery Ticket).\n",
    "   - Stratified sampling: In this population is divided into groups, then sample taken from each group.\n",
    "   - Cluster Sampling: In this population get divided into small groups & some whole groups are randomly selected for study.\n",
    "   - Systematic Sampling: In this select every n-th person from population. For eg(From a list of 1,000 people, you choose every 10th person (10, 20, 30‚Ä¶)).\n",
    "  \n",
    "2) Non-Probability Sampling:\n",
    "   - Convenience Sampling:\n",
    "   - Volunteer Sampling:\n",
    "  \n",
    "##### 3) Sampling Error: It is the diffrence between Sample statistics & population Parameter.\n",
    "\n",
    "##### 4) Data Collection Methods: Expriments, Surveys, Census, Judgement Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b71bce2-6ae4-4e72-875b-5b1c9eb02c45",
   "metadata": {},
   "source": [
    "# EXPLORATORY DATA ANALYSIS \n",
    "        It is very much Used in model development\n",
    "1) **Measures of central tendency:**\n",
    "   - mean: Mean is the average of all numbers.\n",
    "   - median: It is the middle value of a dataset when the numbers are arranged in ascending (or descending) order.\n",
    "   - Mode: If the value is repeating frequently in dataset then it is mode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d3dcb8-f21a-41cf-8a91-8bb4247330c5",
   "metadata": {},
   "source": [
    "2) **Measures of dispersion (It tells us how data is spread out):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05493f3-1df9-403d-9bf5-100b8af3efda",
   "metadata": {},
   "source": [
    "1) Range: Range is the diffrence between highest value & lowest value within a set of numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd6919d-c865-471f-8e66-62f626edf347",
   "metadata": {},
   "source": [
    "2) Interquartile Range(IQR): It is the middle half of data. Interquartile range includes the 50% data points that fall between Q1 & Q3.\n",
    "  - IQR = Q3 - Q1\n",
    "  - Q1  is 25% of data\n",
    "  - Q2 is 50 % of data\n",
    "  - Q3 is 75% of data\n",
    "  - When we subtract Q1 from Q3, we get the middle 50% of the data, which is used for analysis.\n",
    "  - Data points that fall outside this range are considered outliers.\n",
    "  - We use IQR to remove outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d87f0f3-404d-4f11-a830-23752e138f39",
   "metadata": {},
   "source": [
    "3) Variance:\n",
    "   -  It is the average squared difference of the values from the mean. First, we calculate the mean of the data points. Then, we subtract the mean from each data point to get the differences. After that, we square these differences and take the sum. Finally, we divide the sum of squared differences by the number of data points to get the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f499d1-4dbb-41af-9d09-1267686b6731",
   "metadata": {},
   "source": [
    "4) Standerd Deviation:\n",
    "   - Standard Deviation tells us how much the data values are spread out or vary from the average (mean).\n",
    "   - If the data points are very close to each other variation is small & standerd deviation is low.\n",
    "   - SD is lower means it will create stable model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de16d5f7-6598-414b-9bbb-a2609597fca7",
   "metadata": {},
   "source": [
    "## PROBABILITY DISTRIBUTION:\n",
    "#### Normal Distribution(Gaussian Distribution): \n",
    "     It is the most common and important probability distribution in statistics. It has bell-shaped curve and symmetric in nature. Mean=Median=Mode, all three are equal and located at the center of the curve.\n",
    "#### Properties of normal distribution-\n",
    "1) **Emperical rule(68-95-99.7)**:\n",
    "      - It says that 68% of data points lie within 1 standard deviation of the mean.\n",
    "      - 95% of data is within 2 standard deviations.\n",
    "      - 99.7% of data is within 3 standard deviations.\n",
    "         - For eg. Suppose student marks are normally distributed with: Mean = 50 Standard deviation = 10\n",
    "           - Then:\n",
    "             - 68% students scored between 40 and 60.\n",
    "             - 95% students scored between 30 and 70.\n",
    "             - 99.7% students scored between 20 and 80."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec978cc-a31f-4509-866e-7efe8cda4d6d",
   "metadata": {},
   "source": [
    "1) **Distortion(it means something is not in its original shape) in normal distribution**: Distortion occurs when bell curve is not perfect.\n",
    "     - There are two types of distortion: Skweness & Kurtosis.\n",
    "        - Skewness: Skewness tells us whether the data is symmetrical or tilted to one side.\n",
    "           - Skewness is 0: It is called Normal distribution & data is perfectly symmetric.\n",
    "           - Left-skewed(Tail is longer on the left): It is called negative skewness. Order: Mean < Median < Mode\n",
    "           - Right-skewed(Tail is longer on the right): It is called positive skewness. Order: Mode < Median < Mean\n",
    "        - Kurtosis: It tells us how heavy or light the tails of the data are compared to a normal distribution.\n",
    "           - Types:\n",
    "             - Mesokurtic Distribution(Kurtosis = 3): It means data has Normal bell curve.\n",
    "             - Leptokurtic Distribution(Kurtosis > 3): centre part is tall & sharp, tails are heavy(probability of outliers is high, data points keep appearing far away from mean).\n",
    "             - Platykurtic Distribution(Kurtosis < 3): centre part is flat & wide, tails are light(probability of outliers is low, because almost all data stays close to the mean)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9d19e2-adc5-4653-97c8-c5ff56f89a2f",
   "metadata": {},
   "source": [
    "3) **Correcting Distortion in Normal Distribution**: Techniques to reduce skewness (distortion) and make data closer to normal distribution\n",
    "   - **Log Transformation**: Take log of values. Example: if you have numbers like 10, 100, 1000 ‚Üí log makes them 1, 2, 3. This reduces the effect of very large values.\n",
    "   - **Square-root Transformation**: Take square root of values. Example: 1 ‚Üí 1, 4 ‚Üí 2, 9 ‚Üí 3, 100 ‚Üí 10. This also reduces large numbers, but not as strongly as log.\n",
    "   - **Reciprocal Transformation**: Flip the numbers by taking 1/value. Example: 1 ‚Üí 1, 2 ‚Üí 0.5, 10 ‚Üí 0.1. Big numbers become very small, small numbers become big.\n",
    "   - **Box-Cox Transformation**: A smart method that tries different transformations (log, square root, etc.) and automatically picks the best one to make data look normal. Works only when values are positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bd1ce3-4fec-4eb9-b492-b4363c5fae11",
   "metadata": {},
   "source": [
    "4) **Central Limit Theorem**: No matter what the shape of the population is, if we take large enough random samples and calculate their means, the distribution of those sample means will always be approximately normal (bell-shaped). In this the number of sample should be grater than eqaul to 30."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec29ffcf-42d1-4784-836e-667ca4c58650",
   "metadata": {},
   "source": [
    "5) **Probability Density Function**: PDF is a curve that tells us the chance of a continuous variable falling in a range, by looking at the area under the curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81916992-e597-449b-beeb-f4cbf0f2c0b6",
   "metadata": {},
   "source": [
    "6) **Standerd Normal Distribution**: It is a special case of the normal distribution. We convert a normal distribution into a standard normal distribution for scaling, by making the mean 0 and the standard deviation 1. We convert (or scale) a normal distribution into a standard normal distribution using the Z-score formula. We call it Standerdization.\n",
    "   - Z-Score:\n",
    "      - It is a part of the standard normal distribution.\n",
    "      - Z-scores usually range between -3 to +3.\n",
    "      - Formula: ùëç = Data¬†Point¬†‚Äì¬†Mean / Standard¬†Deviation.\n",
    "      -  Why we need it: In a normal distribution, values are in their original units (like cm, kg, marks).\n",
    "      -  In a standard normal distribution, we convert those values into Z-scores (unitless).\n",
    "      -  Every value on the standard normal curve is represented as a Z-score, which tells us how many standard deviations away from the mean the value is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e77f92-42ef-4cf4-ab1b-9354f529bdd7",
   "metadata": {},
   "source": [
    "##### **Note**: When you have a symmetrical distribution for continuous data, the mean, median, and mode are equal. In this case, analysts tend to use the mean because it includes all of the data in calculations. However, if you have a skewed distribution, the median is often the best measure of central tendency.\n",
    "   ##### **Note**: When you have ordinal, categorical, count (discrete), the median or mode is usually the best choice. For categorical data, you have to use the mode.\n",
    "   ##### **Note**: To identify outliers the best way is Box Plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c9ed5b-315a-4200-8555-9f1e872e1f18",
   "metadata": {},
   "source": [
    "# EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bc6b79-a983-49d8-98cf-1cd6648c6cf7",
   "metadata": {},
   "source": [
    "1) Standerd Error:\n",
    "    - It tells how much the sample mean is expected to vary from the population mean.\n",
    "    - In other words, SE shows the average difference between sample means and the true mean.\n",
    "    - To reduce SE take large sample size or reduce data variability(Spread of Data).\n",
    "    - SE = ‚Äúexpected difference‚Äù between sample and population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758d6978-cf60-42bd-921b-3e784974182a",
   "metadata": {},
   "source": [
    "2) Distance Measurement:\n",
    "    - **Euclidean Distance**: It is a classical method to calculate the straight-line distance between two objects.\n",
    "    - **Manhattan Distance**: It is a method to calculate the distance between two objects by moving along horizontal and vertical paths (like city blocks), instead of the straight line.\n",
    "    - **Minkowski distance**: It is a generalised distance formula that includes both Euclidean and Manhattan distances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a78673-5ca6-4670-84e9-5a2ad82ae594",
   "metadata": {},
   "source": [
    "# HYPOTHESIS(assumption or claim or guessing) TESTING :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2011d-c76c-404b-b11c-eb19d30fb6f2",
   "metadata": {},
   "source": [
    "##### HYPOTHESIS MEANING: In hypothesis we test ideas or claims using data. We assume something first (hypothesis), then test it with data to check if it‚Äôs true or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2edd1-6c46-4f81-9727-1dd5c5badc19",
   "metadata": {},
   "source": [
    "##### **Steps in Hypothesis Testing**:\n",
    "1) State the Hypothesis:\n",
    "   - Null Hypothesis( H‚ÇÄ): It is default assumption.\n",
    "   - Alternate Hypothesis(H‚ÇÅ): It is Opposite of H‚ÇÄ.\n",
    "2) Choose Significance Level (Œ±):\n",
    "   - Usually 0.05 (5%).\n",
    "   - This means we accept a 5% chance of being wrong when rejecting H‚ÇÄ.\n",
    "3) Select Test & Collect Data:\n",
    "   - Pick the right test (Z-test, t-test, Chi-square, ANOVA, etc.).\n",
    "   - Gather sample data.\n",
    "4) Analyze the data(Calculate):\n",
    "   - Compare sample mean with claimed mean.\n",
    "   - Calculate test statistic (z, t, œá¬≤).\n",
    "   - p-value = probability that results are just by chance.\n",
    "5) Make Decision:\n",
    "   - If p ‚â§ 0.05 ‚Üí Reject H‚ÇÄ (significant result).\n",
    "   - If p > 0.05 ‚Üí Do not reject H‚ÇÄ (not significant)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc12913-2031-4809-b70c-16d20fb341b0",
   "metadata": {},
   "source": [
    "#### **P-Value**: \n",
    "    It is the probability of the observed result.\n",
    "    - If the p-value ‚â§ 0.05 (Œ±) ‚Üí Reject the null hypothesis (H‚ÇÄ).\n",
    "    - If the p-value > 0.05 (Œ±) ‚Üí accept the null hypothesis (H‚ÇÄ).\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca2db8b-f30c-4dd8-88a4-81fb8539ae6d",
   "metadata": {},
   "source": [
    "#### Errors in Hypothesis Testing\n",
    "1) Type I Error:\n",
    "   - False Positive\n",
    "   - Rejecting H‚ÇÄ when it is actually true.\n",
    "   - Example, A healthy person tested positive for a disease.\n",
    "   - Chance of this error is aplpha(Œ±), usually 5%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942b5e0f-dd8b-499f-80f7-7fe80dc08eba",
   "metadata": {},
   "source": [
    "2) Type II Error:\n",
    "   - False Negative\n",
    "   - Failing to reject H‚ÇÄ when it is actually false.\n",
    "   - Example, A sick person tested negative for a disease.\n",
    "   - Chance of this error is Beta(Œ≤). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1356bc92-ded8-48bb-8759-fa35e0309587",
   "metadata": {},
   "source": [
    "#### Significance Level (Œ±) & Confidence Interval\n",
    "1) Significance Level (Œ±): It means how much error in rejecting H‚ÇÄ we are okay with, or simply, how much risk we are willing to take to reject H‚ÇÄ. Usually 0.05 or 5%\n",
    "   - Example: If Œ± = 0.05 ‚Üí we allow a 5% risk of rejecting H‚ÇÄ even if it‚Äôs true.\n",
    "   - Formula for Œ± = 1 - CI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f445b8e-14a5-4f16-8639-edf94a82b3b5",
   "metadata": {},
   "source": [
    "2) Confidence Interval (CI): It is a range of values in which we expect the population parameter (like mean) to fall. Usually 0.95 or 95%\n",
    "   - Example: Average height = 170 cm, 95% CI = [168, 172]. This means the true mean is very likely between 168 and 172.\n",
    "   - Formula for CI = 1 - Œ±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62144984-4ae5-462a-8c06-5820a46f1e7b",
   "metadata": {},
   "source": [
    "### Types of Hypothesis tesitng\n",
    "    there are two types of hypothesis testing: Parametric & Non-Parametric hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd4162-3968-4f74-92eb-9745931a96bb",
   "metadata": {},
   "source": [
    "#### Parametric Hypothesis Testing:\n",
    "1) T-Test: Used when sample size is less than 30.\n",
    "   - **One sample T-Test**: Compare one sample mean with population mean.\n",
    "   - **Two sample Independent T-Test**: In this we compare means of two independent groups. We check in both groups is there any significant differnce or not.\n",
    "   - **Independent T-Test(Paired Groups)**: In this we compare means of the same group before & after treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b4ddbe-b66b-4856-831d-9930e84395d7",
   "metadata": {},
   "source": [
    "2) Z-Test: Used when sample size is greater than 30."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06714d02-3078-4da5-92dd-c1f89acf7883",
   "metadata": {},
   "source": [
    "3) One Way ANOVA: Anova means **Analysis of Variance**.\n",
    "   - Used to compare the means of 3 or more groups.\n",
    "   - In this we check mean & Variance of multiple groups are same or not.\n",
    "   - Based on partitioning the total variation into:\n",
    "     - between-group variation(Difference between group means.)\n",
    "     - within group variation(Variation inside each group.)\n",
    "     - If between-group variation is large compared to within-group variation, then groups are significantly different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f601d4c-94c7-4798-b514-b6c1fdb1da44",
   "metadata": {},
   "source": [
    "#### Non-Parametric Hypothesis Testing:\n",
    "1) Chi-Square Test:\n",
    "   - It is used to check if there is a relationship between two categorical variables.\n",
    "   - It checks whether the observed data is close enough to the expected data.\n",
    "   - Expected value formula: Row total * Column Total / Grand Total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1a9479-fbe3-4911-bbe2-b225a0a8b721",
   "metadata": {},
   "source": [
    "## COVARIANCE & CORRELATION \n",
    "1) **Covariance**:\n",
    "   - If two variables are correlated with each other, then it is called covariance.\n",
    "   - It shows whether two variables change together.\n",
    "   - In this there are three types of variances:\n",
    "     - A) Positive Covariance ‚Üí Both increase or decrease together.\n",
    "       - Example: Temperature Increses ‚Üí Ice cream sales Increases.\n",
    "     - B) Negative Covariance ‚Üí One increases while the other decreases.\n",
    "       - Example: Exercise hours Increases ‚Üí Weight Decreases.\n",
    "     - C) Zero Covariance: If two variables are not correlated with each other means both are independent then it is Zero Covariance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f673fc8-5f40-4859-8471-743a2f29562c",
   "metadata": {},
   "source": [
    "2) **Correlation**:\n",
    "   - It is scaled(normalized) version of covariance.\n",
    "   - By using correlation we know how strongly two variables are related to each other and in which direction (positive or negative).\n",
    "   - We use heatmap to display the correlation through graph.\n",
    "   - The values of correlation is always **between** -1 and +1,\n",
    "     - +1 ‚Üí Perfect positive relation.\n",
    "     - -1 ‚Üí Perfect negative relation.\n",
    "     - 0 ‚Üí No relation.\n",
    "     - If the correlation is 1 then it is highly correlated & If the value is -1 then we say there is no strong correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30528018-c368-4456-b13d-97bb9034fb62",
   "metadata": {},
   "source": [
    "# Evaluation Matrics:\n",
    "### 1) Linear Regression-\n",
    "    ~ Linear means straight line relationship between input & output if one value increses, other increases & one decreases other also decreases at constant rate.\n",
    "    \n",
    "    ( Formula = Y = B‚ÇÄ + B‚ÇÅx + E\n",
    "      B‚ÇÄ ‚Äì intercept\n",
    "      B‚ÇÅ ‚Äì coefficient\n",
    "      Y ‚Äì target\n",
    "      E ‚Äì error\n",
    "      X ‚Äì independent variable )\n",
    "      \n",
    "    - Follwoing are important mterics in linear regression,\n",
    "1) **MSE**:\n",
    "   - It is the diffrence between actual & predicted which we call error. It suqares the all error values & get the mean of sqaure of error.\n",
    "   - MSE Range 0 to Infinity\n",
    "   - MSE closer to 0 better the model  \n",
    "2) **RMSE**:\n",
    "   - It is root of MSE\n",
    "   - It shows error of actual values because we root the squared error values so it becomes original mean of error values.\n",
    "   - Range 0 to Infinity\n",
    "   - RMSE closer to 0 better the model\n",
    "   - This is always little smaller than MSE\n",
    "3) **R¬≤ Score**:\n",
    "   - It measures how much variance in dependent variable(Y) is explained by independent variable(s)(X)\n",
    "   - Range 0 to 1\n",
    "   - Closer to 1 better the model\n",
    "   - *Formula* = SSR / SSR + SSE\n",
    "   - example-\n",
    "     - If my R¬≤ is 0.77 then my model is able to explain 0.77 variance in dependent variable based on independent variable but my model is not able to explain 0.23 in dependent variable based on independent variable\n",
    "    - *NOTE*: There is problem with R¬≤ Suppose we are predicting house price model 1 uses area(variable) R¬≤ = 0.80 & model 2 uses area + color of the door(variables) then R¬≤ = 0.82. Here color of the door doesn't really help but R¬≤ increased anyway that's why we are using Adjusted R¬≤. If new variable improves model then Adjusted R¬≤ increases & New variable is useless then Adjusted R¬≤ decreases.\n",
    "4) **Adjusted R¬≤**:\n",
    "   - Formula = 1-[(1‚àíR¬≤)√ó(N‚àí1)/(N‚àíK‚àí1)]\n",
    "   - N = No. of rows\n",
    "   - K = No. of columns\n",
    "   - Adjusted R¬≤ tells how well the model fits after adjusting for extra variables\n",
    "   - It is more honest\n",
    "5) **MAPE**:\n",
    "   - Mean Absolute Error in Percentage\n",
    "   - lower the MAPE better the model\n",
    "  \n",
    "6) **MAE**:\n",
    "   - Mean Absolute Error in actual units\n",
    "   - lower the MAE better the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d85efd-6e7a-4d7c-9d5c-23ce3628a6a0",
   "metadata": {},
   "source": [
    "### 2) Logistic Regression-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8927018-7b15-452a-bd44-e2f7058f403d",
   "metadata": {},
   "source": [
    "# EXTRA POINTS:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27268f81-9de7-454c-aaa5-b79fcee51b93",
   "metadata": {},
   "source": [
    "1) DISCRETE DISTRIBUTION:\r",
    "   - Bernoulli, Binomial, Poisson.\n",
    "   - Uniformrm, Exponenti.l\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291564d6-2801-47da-8609-56463ab41399",
   "metadata": {},
   "source": [
    "3) Statistical Plots:\n",
    "   - Histogram\n",
    "   - Box Plot\n",
    "   - QQ Plot\n",
    "   - Scattar Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79e8a7a-a505-4cd0-b721-fc7e3b075a72",
   "metadata": {},
   "source": [
    "4) Cumulative Density Function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf78f9-d746-44d0-b1e5-8c80f627f129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
